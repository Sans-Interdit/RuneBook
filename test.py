title = "Introduction à League of Legends"

content = """
League of Legends, souvent abrégé en LoL, est un jeu vidéo sorti en 2009 appartenant au genre des arènes de bataille en ligne (MOBA). Développé et édité par Riot Games, le jeu adopte un modèle économique free-to-play à sa sortie et devient rapidement un phénomène mondial. Disponible sur Windows et Mac OS, il met en scène deux équipes de cinq joueurs qui s’affrontent dans des parties d’environ trente minutes, avec pour objectif principal de détruire le Nexus adverse, structure centrale défendue dans chaque base.

Chaque joueur contrôle un « champion », un personnage unique doté d’un style de jeu particulier, de compétences spécifiques et d’une identité propre. Le jeu en compte plus de 160. Au fil de la partie, les champions gagnent en puissance grâce à l’expérience acquise et à l’achat d’objets, ce qui fait évoluer de manière dynamique le déroulement des combats.

Bien que le mode principal soit la référence compétitive, LoL propose aussi des modes alternatifs, notamment Teamfight Tactics depuis 2019, un auto battler basé sur l’univers du jeu mais très différent dans sa mécanique.

League of Legends puise une partie de son inspiration dans Defense of the Ancients, un mod de Warcraft III. À sa sortie, Riot adopte un modèle « freemium » : le jeu est gratuit, mais des éléments esthétiques et des champions peuvent être débloqués avec de la monnaie virtuelle ou via des achats.

Le succès de LoL dépasse rapidement celui de ses concurrents et contribue à l’essor de l’esport moderne. Ses championnats internationaux dépassent régulièrement les records d’audience, notamment en 2019, où plus de 44 millions de spectateurs simultanés assistent au championnat du monde.

Sa popularité propulse toute une gamme de contenus dérivés : musiques, comics, nouvelles, figurines et même la série animée Arcane, acclamée par la critique. Le jeu inspire aussi de nombreux spin-offs se déroulant dans le même univers narratif, comme Legends of Runeterra, Ruined King ou Wild Rift, version mobile repensée pour les écrans tactiles.
"""

tags = ["Présentation", "Histoire"]






title = "Le système de jeu : bases et mécaniques"

content = """
Le système de jeu de League of Legends repose sur le contrôle d’un champion depuis une perspective isométrique. Chaque champion possède des attaques de base et cinq compétences uniques. Le joueur prépare sa partie à travers plusieurs choix préalables : les sorts d’invocateur, très puissants mais limités, ainsi que les runes, qui modifient ses statistiques et capacités. Chaque partie est indépendante : aucune ressource ou progression n’est conservée d’un match à l’autre.

On distingue six grandes classes de champions : tanks, combattants, assassins, mages, tireurs et supports. Chacune remplit un rôle particulier dans la composition d’équipe et influence la manière dont la partie se déroule.

La carte principale, la Faille de l’invocateur, est un terrain symétrique divisé en trois voies : haut, milieu et bas. Chaque voie est défendue par trois tourelles par équipe. Le Nexus est protégé par deux tourelles supplémentaires, ainsi qu’une fontaine où les joueurs réapparaissent.

Les sbires, générés automatiquement par chaque Nexus, se déplacent en continu sur les voies. Leur élimination procure de l’or et de l’expérience, essentiels pour améliorer son champion. Les bases comportent également trois inhibiteurs : lorsqu’ils sont détruits, les sbires ennemis deviennent plus puissants.

La jungle, située entre les voies, renferme des monstres neutres réapparaissant régulièrement. Certains, comme le Baron Nashor ou les dragons, offrent des bonus majeurs à l’équipe qui les vainc. Leur contrôle est souvent décisif dans les parties à haut niveau.

Le schéma classique d’une partie voit un joueur sur la voie du haut, un au milieu, deux en bas, et un joueur dans la jungle. Cependant, les déplacements se multiplient au fil du jeu, laissant place à des combats d’équipe et des objectifs stratégiques. L’or permet d’acheter des objets augmentant drastiquement la puissance des champions, tandis que l’expérience accroît leur niveau et débloque des compétences.

La durée d’une partie varie fortement : une équipe dominante peut conclure en une quinzaine de minutes, mais les affrontements équilibrés peuvent durer jusqu’à une heure.
"""

tags = ["Gameplay", "Champions"]







title = "Les modes de jeu permanents et supprimés"

content = """
En plus de la Faille de l’invocateur, LoL possède plusieurs modes permanents. L’un des plus populaires est l’ARAM, un mode où les joueurs s’affrontent en 5 contre 5 sur une carte à voie unique, avec un champion attribué aléatoirement. Les parties y sont rapides et riches en combats. Ce mode ne dispose d’aucune scène compétitive, mais possède une communauté très active. Il apprend notamment aux joueurs à éviter les compétences ennemies et à manier des champions divers.

L’autre mode permanent est Teamfight Tactics (TFT), un auto battler où le joueur compose une équipe de champions placés automatiquement sur une arène. Huit joueurs s’affrontent tour par tour, et chaque défaite fait perdre des points de vie. Le dernier joueur en vie l’emporte. TFT est intégré à LoL mais existe aussi comme jeu mobile indépendant, avec son propre classement et sa propre scène esport.

Plusieurs modes ont été retirés avec le temps. Dominion, apparu en 2011, proposait une carte circulaire et un système de capture de points plutôt que la destruction d’un Nexus. Le mode a été supprimé en 2016. La Forêt torturée, un 3 contre 3 avec deux voies, une jungle et un système d’autels, constituait le premier mode alternatif du jeu avant d’être retiré en 2019.

Un grand nombre de modes temporaires apparaissent durant les événements : Ultra Rapid Fire (URF), très rapide et chaotique, Un Pour Tous, où toute l’équipe joue le même champion, ou encore le Raid du Nexus, un mode expérimental avec objectifs aléatoires. Ces modes enrichissent l’expérience tout en offrant une variété constante au gameplay.
"""

tags = ["Modes", "Carte"]





title = "Progression, développement et distribution"

content = """
Bien que chaque partie soit indépendante, les joueurs progressent grâce à l’expérience gagnée en fin de match. Monter de niveau permet de débloquer des champions et du contenu supplémentaire. D’autres éléments, comme les skins, n’affectent pas le gameplay mais modifient l’apparence des champions. Le joueur peut aussi gravir un système de classement public reflétant son niveau global.

L’idée de créer un successeur à Defense of the Ancients naît en 2005, lorsque des membres de la communauté DotA voient le potentiel d’un jeu indépendant complet reposant sur ce concept. Riot Games, fondé par Brandon Beck et Marc Merrill, ouvre officiellement en 2006. Le développement de LoL repose sur une philosophie participative interne : les employés votaient pour les nouveaux champions à intégrer.

Riot signe rapidement des accords de distribution internationaux, notamment avec Tencent en Chine, GOA en Europe, avant de reprendre lui-même l’exploitation du jeu sur ce territoire. League of Legends devient gratuit en 2009, sans coûts additionnels cachés, et Riot mise sur l’achat de contenu cosmétique pour financer le jeu. LoL est disponible dans de nombreuses régions, avec des serveurs dédiés dans le monde entier.

En 2019, le jeu est bloqué en Syrie et en Iran par décision américaine liée à des tensions géopolitiques.
"""

tags = ["Modes", "Carte"]


















# import requests
# from bs4 import BeautifulSoup
# import re


# url = "https://leagueoflegends.fandom.com/wiki/blitzcrank/LoL"

# # 1) Télécharger la page
# headers = {"User-Agent": "Mozilla/5.0"}  # pour éviter d'être bloqué
# response = requests.get(url, headers=headers)
# response.raise_for_status()

# # 2) Parser le contenu
# soup = BeautifulSoup(response.text, "lxml")


# main = soup.select_one(".mw-content-ltr")

# first_p = next((child for child in main.children if child.name == "p"), None)
# text = re.sub(r'\[.*?\]', '', first_p.text)  # enlever les références  [1], [2], etc.
    

# print(text + "\n")



# first_lore_block = soup.select_one(".skinviewer-info-lore")
# first_text_block = first_lore_block.find("div")  # premier vrai div contenant le texte


# print(first_text_block.get_text(strip=True) + "\n\n")


# champ_info_text = champ_info_block.find("div")  # premier vrai div contenant le texte
# print(champ_info_text.get_text(strip=True))


# skills = soup.select(".ability-info-container")

# for skill in skills:
#     # On remplace les <br> par des retours à la ligne
#     for br in skill.find_all("br"):
#         br.replace_with("\n")

#     # Optionnel : convertir les <div> internes en retours à la ligne
#     for div in skill.find_all("div"):
#         div.replace_with(f"\n{div.get_text()}\n")

#     # Extraction propre
#     text = skill.get_text("\n", strip=True)

#     # Nettoyage final : supprimer les lignes vides multiples
#     clean_text = "\n".join([line for line in text.split("\n") if line.strip()])

#     print("---- SKILL ----")
#     print(clean_text)
#     print()




















# stats_table = soup.select_one(".pi-item.pi-data.pi-item-spacing.pi-border-color")
# if stats_table:
#     print("Bloc d'infos :", stats_table.get_text(strip=True))


# infobox = soup.select_one(".portable-infobox")

# for item in infobox.select(".pi-item"):
#     label = item.select_one(".pi-data-label")
#     value = item.select_one(".pi-data-value")
#     if label and value:
#         print(f"{label.text.strip()}: {value.text.strip()}")














"""
Scraper -> API MediaWiki (Fandom)
Dépendances : requests, beautifulsoup4, lxml
pip install requests beautifulsoup4 lxml
"""

import requests
from bs4 import BeautifulSoup, Tag
import re
from typing import Optional, Dict, List
import json


HEADERS = {"User-Agent": "Mozilla/5.0"}

def format_champion_for_rag(name, lore, infobox, stats, spells):
    out = []

    out.append(f"Champion: {name}\n")
    # out.append("Summary :")
    # out.append(summary.strip() + "\n")

    out.append("Lore :")
    out.append(lore.strip() + "\n")

    out.append("Informations :")
    for key, value in infobox.items():
        out.append(f"- {key} : {value}")
    out.append("")

    out.append("Stats :")
    for key, value in stats.items():
        out.append(f"- {key} : {value}")
    out.append("")

    spell_names = ["Passive spell", "First spell (Q)", "Second spell (W)", "Third spell (E)", "Fourth spell (R) (Ultimate)"]

    out.append("Spells :")
    for i, spell in enumerate(spells):
        out.append("")
        out.append(f"{spell_names[i]} :")
        for key, value in spell.items():
            out.append(f"- {key} : {value}")
    out.append("")

    return "\n".join(out)  


# def extract_champion_stats(soup: BeautifulSoup) -> dict:
#     """
#     Récupère Difficulty, Toughness, Control, Mobility, Utility depuis l'infobox
#     """
#     stats = {}
#     box = soup.select_one(".type-lol-champion") or soup.select_one(".portable-infobox")
#     if not box:
#         return stats

#     # on cherche les divs contenant les stats
#     for item in box.select(".pi-item"):
#         label = item.select_one(".pi-data-label")
#         value = item.select_one(".pi-data-value")
#         if label and value:
#             label_text = label.get_text(strip=True)
#             value_text = value.get_text(" ", strip=True)
#             if label_text in ["Difficulty", "Toughness", "Control", "Mobility", "Utility"]:
#                 stats[label_text] = value_text
#     return stats


def fetch_page_html(wiki_base: str, page_title: str) -> Optional[str]:
    """
    Récupère le HTML principal d'une page via l'API MediaWiki (action=parse).
    wiki_base: exemple "https://leagueoflegends.fandom.com"
    page_title: exemple "Blitzcrank/LoL"
    """
    api_url = f"{wiki_base.rstrip('/')}/api.php"
    params = {
        "action": "parse",
        "page": page_title,
        "format": "json",
        "prop": "text"  # HTML de la page
    }

    with requests.get(
        api_url,
        params=params,
        headers=HEADERS,
        timeout=15
    ) as resp:
        resp.raise_for_status()
        data = resp.json()    

    if "error" in data:
        print("API error:", data["error"])
        return None
    return data["parse"]["text"]["*"]


# def remove_block(text: str, keywords: List[str], lines_after: int = 3) -> str:
#     pattern = r"(" + "|".join(re.escape(k) for k in keywords) + r")(\n.*){0," + str(lines_after) + "}"
#     return re.sub(pattern, "", text, flags=re.MULTILINE)


# def fix_inline_parentheses(text: str) -> str:
#     lines = text.split("\n")
#     new_lines = []
#     i = 0
#     while i < len(lines):
#         if lines[i].strip() == "(" and i+2 < len(lines) and lines[i+2].strip() == ")":
#             inner = lines[i+1].strip()
#             # on ajoute à la fin de la ligne précédente
#             new_lines[-1] = new_lines[-1].rstrip() + f" ( {inner} )"
#             i += 3
#             continue
#         new_lines.append(lines[i])
#         i += 1
#     return "\n".join(new_lines)


def clean_text_basic(text: str) -> str:
    # enlever les références [1], [2], etc.
    text = re.sub(r'\[\d+\]', '', text)
    # normaliser retours à la ligne
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()


# def parse_first_paragraph(soup: BeautifulSoup) -> Optional[str]:
#     """
#     Récupère le premier <p> enfant direct de .mw-content-ltr
#     """
#     container = soup.select_one(".mw-content-ltr")
#     if not container:
#         return None
#     # ne prendre que les enfants directs, comme dans ton code qui fonctionne
#     first_p = next((child for child in container.children if child.name == "p"), None)
#     if first_p:
#         return re.sub(r'\[.*?\]', '', first_p.text)
#     return None


def get_section_by_headline(soup: BeautifulSoup, headline_texts: List[str]) -> Optional[str]:
    """
    Cherche une section dont l'entête (.mw-headline) contient un des headline_texts,
    retourne le texte de cette section (jusqu'à la prochaine balise h2/h3 du même niveau).
    """
    for span in soup.select(".mw-headline"):
        if span.string and any(span.string.strip().lower() == h.strip().lower() for h in headline_texts):
            # remontons au parent heading (h2/h3) pour capter le niveau
            heading = span.find_parent(re.compile("^h[1-6]$"))
            if not heading:
                continue
            section_text_parts = []
            # parcourir frères suivants jusqu'au prochain heading de même niveau ou supérieur
            for sib in heading.next_siblings:
                if isinstance(sib, Tag) and re.match(r"h[1-6]", sib.name or "", re.I):
                    break
                if isinstance(sib, Tag):
                    section_text_parts.append(sib.get_text("\n", strip=True))
            return "\n\n".join(p for p in section_text_parts if p.strip())
    return None


def extract_lore(soup: BeautifulSoup) -> Optional[str]:
    # 1) fallback par classe spécifique Fandom
    lore_block = soup.select_one(".skinviewer-info-lore")
    if lore_block:
        return lore_block.get_text("\n", strip=True)
    # 2) fallback par section "Lore"
    lore_by_headline = get_section_by_headline(soup, ["Lore", "Lore (background)"])
    if lore_by_headline:
        return lore_by_headline
    # 3) ultime fallback: chercher "Background" ou "Story"
    return get_section_by_headline(soup, ["Background", "Story"])


def extract_infobox(soup: BeautifulSoup) -> Dict[str, str]:
    """
    Extrait les paires label:value de l'infobox portable (Fandom MediaWiki).
    """
    keywords_to_remove = [
        "Store price",
        "Crafting",
        "Ratings",
        "Style",
        "Difficulty"
    ]
    data = {}
    # 1) type-lol-champion (cas spécifique Fandom LoL)
    box = soup.select_one(".type-lol-champion") or soup.select_one(".portable-infobox") or soup.select_one(".infobox")
    if not box:
        return data
    # méthode : chercher les items .pi-item et pi-data-label/pi-data-value (structure Fandom)
    items = box.select(".pi-item")
    if items:
        for item in items:
            label = item.select_one(".pi-data-label")
            value = item.select_one(".pi-data-value")
            if label and value:
                label_text = label.get_text(strip=True)
                if label_text not in keywords_to_remove:
                    if label_text == "Adaptive type":
                        data[label_text] = value.get_text(" ", strip=True).replace("Champions stunned with Pyromania (P) ", "")
                    else:
                        data[label_text] = value.get_text(" ", strip=True)
            else:
                # certains items ont structure différente : attempt split by ":" or br
                text = item.get_text(" ", strip=True)
                if ":" in text:
                    label_part, val_part = text.split(":", 1)
                    data[label_part.strip()] = val_part.strip()
    else:
        # fallback : parcourir tous les li ou div directs
        for child in box.find_all(["div", "li"], recursive=True):
            text = child.get_text(" ", strip=True)
            if ":" in text:
                k, v = text.split(":", 1)
                data[k.strip()] = v.strip()
    return data


# def extract_abilities(soup: BeautifulSoup) -> List[str]:
#     # 1) classes fréquentes
#     ability_nodes = soup.select(".ability-info-container") or soup.select(".skill") or soup.select(".abilities")
#     abilities = []
#     if ability_nodes:
#         for node in ability_nodes:
#             # remplacer <br> par newline pour lisibilité
#             for br in node.find_all("br"):
#                 br.replace_with("\n")
#             text = node.get_text("\n", strip=True)
#             # split if the node contains multiple abilities packed
#             # on retourne des blocs non vides
#             for block in [b.strip() for b in text.split("\n\n") if b.strip()]:
#                 abilities.append(block)
#         return abilities

#     # 2) fallback: chercher section "Abilities" / "Abilities & skill"
#     abil_section = get_section_by_headline(soup, ["Abilities", "Abilities & Gameplay", "Abilities & Gameplay", "Skills"])
#     if abil_section:
#         # découper intelligemment par titres de sous-sections (ex: Q, W, E, R)
#         # recherche de lignes commençant par Q/W/E/R ou "Passive"
#         parts = re.split(r"(Passive|Q|W|E|R)\b", abil_section)
#         # la split donne fragments; on regroupe pour lisibilité simple:
#         cleaned = [p.strip() for p in re.split(r'\n{2,}', abil_section) if p.strip()]
#         return cleaned
#     return abilities


# def html_to_text_and_clean(html: str) -> str:
#     soup = BeautifulSoup(html, "lxml")
#     text = soup.get_text("\n", strip=True)
#     text = clean_text_basic(text)
#     text = fix_inline_parentheses(text)
#     text = re.sub(r'\n{2,}', '\n\n', text)
#     return text


# def clean_ability_node(node: BeautifulSoup):
#     # supprimer toutes les images (icônes de spells, champions, items, etc.)
#     for img in node.select("img"):
#         img.decompose()

#     # supprimer les liens qui ne contiennent plus que du bruit
#     for a in node.select("a"):
#         # si le lien ne contient plus de texte utile
#         if not a.get_text(strip=True):
#             a.decompose()

#         # ou si c'est clairement un tooltip de skill
#         elif any(attr in a.attrs for attr in ("data-tooltip", "title", "aria-label")):
#             a.unwrap()

def extract_abilities_simple(soup: BeautifulSoup) -> list:
    ability_nodes = soup.select(".ability-info-container")
    abilities_slot = ["Passive", "Q", "W", "E", "R"]
    abilities = []

    if not ability_nodes:
        return abilities

    for index, node in enumerate(ability_nodes):
        for unwanted in node.find_all("span", class_="ll-item navbox"):
            unwanted.decompose()  # supprime complètement l'élément du tree
        for br in node.find_all("br"):
            br.replace_with("\n")

        text = node.get_text()

        text = re.sub(r'champions[^)]*', '', text)

        text = re.sub(
            r"\b[A-Z][A-Za-z' ]+\s*\([QWERP]\)",
            "",
            text
        )

        parts = re.split(r'\n{2,}', text)
        data = {"name" : parts[0]}
        data["slot"] = abilities_slot[index]
        for part in parts[2:]:
            part = part.strip()
            if part:
                part_list = part.split(":")
                if len(part_list) == 2:
                    data[part_list[0].strip()] = part_list[1].strip()


        abilities.append(data)

    return abilities








if __name__ == "__main__":
    # import requests

    # # Récupérer la version la plus récente
    # versions_url = "https://ddragon.leagueoflegends.com/api/versions.json"
    # versions = requests.get(versions_url).json()
    # latest_version = versions[0]

    # # Récupérer les données des champions
    # champions_url = f"https://ddragon.leagueoflegends.com/cdn/{latest_version}/data/en_US/champion.json"
    # data = requests.get(champions_url).json()

    # # Construire une liste Python des noms de champions
    # champions = [champ["name"] for champ in data["data"].values()]
    # print(champions)

    champion = "Blitzcrank"

    WIKI_BASE = "https://leagueoflegends.fandom.com"
    PAGE = f"{champion}/LoL"

    html = fetch_page_html(WIKI_BASE, PAGE)
    if not html:
        raise SystemExit("Impossible de récupérer la page via l'API")

    soup = BeautifulSoup(html, "lxml")

    # 1) premier paragraphe
    # first_p = parse_first_paragraph(soup)

    # if first_p:
    #     print("=== PREMIER PARAGRAPHE ===\n")
    #     print(first_p + "\n")

    # 2) lore (si existant)
    lore = extract_lore(soup)
    if lore:
        lore = clean_text_basic(lore)
        # print("=== LORE ===\n")
        # print(lore + "\n")

    # 3) infobox / bloc d'info champion
    info = extract_infobox(soup)
    # print("=== INFOBOX ===\n")
    # print(info)
    # print()

    # print("=== STATS ===\n")
    champ_info_block = soup.select_one(".stat-wheel")
    text = champ_info_block.get_text(separator=" : ", strip=True)

    # transformer en dictionnaire
    parts = text.split(" : ")
    ratings = {}
    for i in range(0, len(parts)-1, 2):
        key = parts[i].strip()
        value = parts[i+1].strip()
        ratings[key] = value

    # print(ratings)
    # print()

    spells = extract_abilities_simple(soup)
    # print(json.dumps(spells, indent=4, ensure_ascii=False))


    print("\n\n\n\n\n")

    data = {
        "champion": champion,
        "lore": lore,
        "info": info,
        "ratings": ratings,
        "spells": spells,
    }

    print(json.dumps(data, indent=4, ensure_ascii=False))
    print(format_champion_for_rag(champion, lore, info, ratings, spells))

